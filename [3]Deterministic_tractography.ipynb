{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DTI Deterministic Tractography"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Local fibre tracking is an approach used to model white matter fibres by creating streamlines from local directional information. The idea is as follows: if the local directionality of a tissue segment is known, one can integrate along those directions to build a complete representation of the structure."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To perform local fibre tracking we needed:\n",
    "\n",
    "1) A method for estimating directions from a diffusion data set.\n",
    "\n",
    "2) A set of seeds from which to begin propagating streamlines\n",
    "\n",
    "3) A set of stopping criteria for streamline propagation\n",
    "\n",
    "4) A method for propagating streamlines.\n",
    "\n",
    "This notebook will perform a tractography reconstruction from a dMRI dataset using the DTI model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load the Stanford's dMRI dataset:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dipy.core.gradients import gradient_table\n",
    "from dipy.data import get_fnames\n",
    "from dipy.io.gradients import read_bvals_bvecs\n",
    "from dipy.io.image import load_nifti\n",
    "\n",
    "hardi_fname, hardi_bval_fname, hardi_bvec_fname = get_fnames('stanford_hardi')\n",
    "\n",
    "data, affine, hardi_img = load_nifti(hardi_fname, return_img=True)\n",
    "bvals, bvecs = read_bvals_bvecs(hardi_bval_fname, hardi_bvec_fname)\n",
    "gtab = gradient_table(bvals, bvecs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The loaded data is masked:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dipy.segment.mask import median_otsu\n",
    "\n",
    "maskdata, mask = median_otsu(data, vol_idx=range(0, 9),\n",
    "                             numpass=1, dilate=5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We are provided a file that labels white matter voxels of the Stanford's dMRI dataset by either 1 or 2. To speed the processing  we'll use these labels to only extract peaks in the labeled white matter voxels: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dipy.io.image import load_nifti_data\n",
    "\n",
    "label_fname = get_fnames('stanford_labels')\n",
    "\n",
    "labels = load_nifti_data(label_fname)\n",
    "\n",
    "white_matter = (labels == 1) | (labels == 2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1) Getting directions from the dMRI dataset\n",
    "\n",
    "We will use the DTI model to get the directions. For this we instantiate a Tensor model according to the data GradientTable object:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dipy.reconst.dti import TensorModel\n",
    "\n",
    "dti_model = TensorModel(gtab)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Diffusion tensor main direction can be calculated from its eigenvectors. Here, DTI peaks are extracted using dipy's function \"peaks_from_model\". This function provides a more general strategy to extract directions that can be applied to different dMRI models. Below we extract directions on the white matter voxels.\n",
    "\n",
    "* Note: Function \"peaks_from_model\" requires a variable containing discrete directions for evaluation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dipy.direction import peaks_from_model\n",
    "from dipy.data import default_sphere\n",
    "\n",
    "dti_peaks = peaks_from_model(dti_model, maskdata, default_sphere,\n",
    "                             relative_peak_threshold=.8,\n",
    "                             min_separation_angle=45,\n",
    "                             mask=white_matter)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will visualize a slice from the direction field which we will use as the basis to perform the tracking."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dipy.viz import window, actor, has_fury\n",
    "\n",
    "if has_fury:\n",
    "    scene = window.Scene()\n",
    "    scene.add(actor.peak_slicer(dti_peaks.peak_dirs,\n",
    "                                dti_peaks.peak_values,\n",
    "                                colors=None))\n",
    "\n",
    "    window.record(scene, out_path='dti_direction_field.png', size=(900, 900))\n",
    "    window.show(scene, size=(800, 800))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2) Defining the seeds where tracking will start"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The seeds for tracking are defined in Dipy using the function \"seeds_from_mask\" from \"dipy.tracking.utils\". We place a grid of 2 × 2 × 2 grid of seeds per voxel, in a sagittal slice of the corpus callosum. The voxels to seed are selected by the input \"seed_mask\" which here we use the regions with the label value 2 which corresponds to voxels in a sagittal slice of the corpus callosum. Tracking from this region will, therefore, give us a model of the corpus callosum tract."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dipy.tracking import utils\n",
    "\n",
    "seed_mask = (labels == 2)\n",
    "seeds = utils.seeds_from_mask(seed_mask, affine, density=[3, 3, 3])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3) Defining the tracking stopping criterion"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Streamlines will be produced until reaching a voxel with FA lower than 0.2. For this, we have to first compute the FA map."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "dti_fit = dti_model.fit(maskdata)\n",
    "fa = dti_fit.fa"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The stopping criterion area is defined using the function \"ThresholdStoppingCriterion\" from \"dipy.tracking.stopping_criterion\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dipy.tracking.stopping_criterion import ThresholdStoppingCriterion\n",
    "\n",
    "stopping_criterion = ThresholdStoppingCriterion(fa, .2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4) Propagating the streamlines"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Having the directions, starting position and stopping criterion defined we can start generating streamlines. The streamline generation has to be first initialized. For this, we use the function \"LocalTracking\" from \"dipy.tracking.local_tracking\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dipy.tracking.local_tracking import LocalTracking\n",
    "\n",
    "streamlines_generator = LocalTracking(dti_peaks, stopping_criterion, seeds,\n",
    "                                      affine=affine, step_size=.5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Streamlines can then be generated using the \"Streamline\" function from dipy.tracking.streamline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dipy.tracking.streamline import Streamlines\n",
    "\n",
    "# Generate streamlines object\n",
    "streamlines = Streamlines(streamlines_generator)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Below we display the resulting streamlines using the fury python package."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'has_fury' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Input \u001b[1;32mIn [1]\u001b[0m, in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mdipy\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mviz\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m colormap\n\u001b[1;32m----> 3\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[43mhas_fury\u001b[49m:\n\u001b[0;32m      4\u001b[0m     \u001b[38;5;66;03m# Prepare the display objects.\u001b[39;00m\n\u001b[0;32m      5\u001b[0m     color \u001b[38;5;241m=\u001b[39m colormap\u001b[38;5;241m.\u001b[39mline_colors(streamlines)\n\u001b[0;32m      7\u001b[0m     streamlines_actor \u001b[38;5;241m=\u001b[39m actor\u001b[38;5;241m.\u001b[39mline(streamlines,\n\u001b[0;32m      8\u001b[0m                                    colormap\u001b[38;5;241m.\u001b[39mline_colors(streamlines))\n",
      "\u001b[1;31mNameError\u001b[0m: name 'has_fury' is not defined"
     ]
    }
   ],
   "source": [
    "from dipy.viz import colormap\n",
    "\n",
    "if has_fury:\n",
    "    # Prepare the display objects.\n",
    "    color = colormap.line_colors(streamlines)\n",
    "\n",
    "    streamlines_actor = actor.line(streamlines,\n",
    "                                   colormap.line_colors(streamlines))\n",
    "\n",
    "    # Create the 3D display.\n",
    "    scene = window.Scene()\n",
    "    scene.add(streamlines_actor)\n",
    "\n",
    "    # Save still images for this static example. Or for interactivity use\n",
    "    window.record(scene, out_path='dti_tractogram.png', size=(800, 800))\n",
    "    window.show(scene)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We’ve created a deterministic set of streamlines using the LocalTracking algorithm from the diffusion tensor main direction. This procedure is called deterministic because if you repeat the fiber tracking (keeping all the inputs the same) you will get exactly the same set of streamlines. We can save the streamlines as a Trackvis file so it can be loaded into other software for visualization or further analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dipy.io.stateful_tractogram import Space, StatefulTractogram\n",
    "from dipy.io.streamline import save_trk\n",
    "\n",
    "sft = StatefulTractogram(streamlines, hardi_img, Space.RASMM)\n",
    "save_trk(sft, \"dti_CC_tractography_deterministic.trk\", streamlines)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Volume in drive D is Data\n",
      " Volume Serial Number is 6A19-EF97\n",
      "\n",
      " Directory of D:\\Projects\\EPICS\\Notebooks\n",
      "\n",
      "05/20/2023  05:18 PM    <DIR>          .\n",
      "05/20/2023  05:18 PM    <DIR>          ..\n",
      "05/16/2023  10:20 AM    <DIR>          .ipynb_checkpoints\n",
      "05/16/2023  01:32 AM         9,889,472 Bilder_DTI_spline_filter.trk\n",
      "05/14/2023  04:04 PM        18,007,672 dti_CC_tractography_deterministic.trk\n",
      "05/13/2023  04:23 PM            33,642 dti_direction_field.png\n",
      "05/13/2023  04:25 PM           251,579 dti_tractogram.png\n",
      "05/16/2023  01:51 AM         6,733,714 ICBM_DTI-81_Atlas_Fractional_Anisotropy_raw.zip\n",
      "07/29/2013  10:16 AM         6,760,247 ICBM_FA_raw.zip\n",
      "11/05/2009  10:46 AM    <DIR>          ICBM_FA_raw.zipfile\n",
      "03/10/2023  11:30 PM            41,568 multi_tensor_voxel_fit.png\n",
      "03/10/2023  11:30 PM            40,261 multi_tensor_voxel_gt.png\n",
      "03/10/2023  11:31 PM            60,401 odf_multi_tensor.png\n",
      "03/10/2023  11:29 PM            49,452 odf_single_tensor.png\n",
      "03/10/2023  11:28 PM            28,878 single_tensor_voxel_fit.png\n",
      "03/10/2023  11:28 PM            29,673 single_tensor_voxel_gt.png\n",
      "05/16/2023  04:09 AM             8,654 streamline_formats.py\n",
      "05/14/2023  04:20 PM         2,610,496 tensor_ad.nii\n",
      "05/14/2023  04:20 PM           973,690 tensor_ad.nii.gz\n",
      "05/14/2023  04:20 PM           186,516 tensor_ellipsoids.png\n",
      "05/14/2023  04:20 PM         2,610,496 tensor_fa.nii\n",
      "05/14/2023  04:20 PM           999,582 tensor_fa.nii.gz\n",
      "05/14/2023  04:20 PM         2,610,496 tensor_md.nii\n",
      "05/14/2023  04:20 PM           973,248 tensor_md.nii.gz\n",
      "05/14/2023  04:20 PM         2,610,496 tensor_rd.nii\n",
      "05/14/2023  04:20 PM           986,850 tensor_rd.nii.gz\n",
      "05/16/2023  11:06 AM           280,818 [1]dMRI.ipynb\n",
      "05/16/2023  11:08 AM            50,634 [2]Simulated_DTI_tissue.ipynb\n",
      "05/20/2023  05:18 PM            13,309 [3]Deterministic_tractography.ipynb\n",
      "05/16/2023  10:26 AM               856 [4]Parameter_Analysis.ipynb\n",
      "              26 File(s)     56,842,700 bytes\n",
      "               4 Dir(s)  148,251,168,768 bytes free\n"
     ]
    }
   ],
   "source": [
    "!dir"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading file ...\n",
      "dti_CC_tractography_deterministic.trk\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "!dipy_horizon dti_CC*trk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading file ...\n",
      "dti_CC_tractography_deterministic.trk\n",
      "\n",
      "\n",
      "Loading file ...\n",
      "tensor_fa.nii.gz\n",
      "\n",
      "\n",
      "Affine to RAS\n",
      "[[   2.    0.    0.  -80.]\n",
      " [   0.    2.    0. -120.]\n",
      " [   0.    0.    2.  -60.]\n",
      " [   0.    0.    0.    1.]]\n",
      "Original shape (81, 106, 76)\n",
      "Resized to RAS shape  (81, 106, 76)\n"
     ]
    }
   ],
   "source": [
    "!dipy_horizon dti_CC*trk tensor_fa.nii.gz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from dipy.tracking import streamline, metrics\n",
    "# from dipy.tracking import distances\n",
    "# from dipy.reconst.dti import mean_diffusivity\n",
    "\n",
    "# lengths = streamline.length(streamlines)\n",
    "# md_values = mean_diffusivity(data, streamlines)\n",
    "# fa_values = metrics.mean_fa(streamlines, data)\n",
    "# rd_values = metrics.mean_rd(streamlines, data)\n",
    "# ad_values = metrics.mean_ad(streamlines, data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading file ...\n",
      "dti_CC_tractography_deterministic.trk\n",
      "\n",
      "\n",
      "Loading file ...\n",
      "tensor_md.nii.gz\n",
      "\n",
      "\n",
      "Affine to RAS\n",
      "[[   2.    0.    0.  -80.]\n",
      " [   0.    2.    0. -120.]\n",
      " [   0.    0.    2.  -60.]\n",
      " [   0.    0.    0.    1.]]\n",
      "Original shape (81, 106, 76)\n",
      "Resized to RAS shape  (81, 106, 76)\n"
     ]
    }
   ],
   "source": [
    "!dipy_horizon dti_CC*trk tensor_md.nii.gz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading file ...\n",
      "dti_CC_tractography_deterministic.trk\n",
      "\n",
      "\n",
      "Loading file ...\n",
      "tensor_ad.nii.gz\n",
      "\n",
      "\n",
      "Affine to RAS\n",
      "[[   2.    0.    0.  -80.]\n",
      " [   0.    2.    0. -120.]\n",
      " [   0.    0.    2.  -60.]\n",
      " [   0.    0.    0.    1.]]\n",
      "Original shape (81, 106, 76)\n",
      "Resized to RAS shape  (81, 106, 76)\n"
     ]
    }
   ],
   "source": [
    "!dipy_horizon dti_CC*trk tensor_ad.nii.gz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading file ...\n",
      "dti_CC_tractography_deterministic.trk\n",
      "\n",
      "\n",
      "Loading file ...\n",
      "tensor_rd.nii.gz\n",
      "\n",
      "\n",
      "Affine to RAS\n",
      "[[   2.    0.    0.  -80.]\n",
      " [   0.    2.    0. -120.]\n",
      " [   0.    0.    2.  -60.]\n",
      " [   0.    0.    0.    1.]]\n",
      "Original shape (81, 106, 76)\n",
      "Resized to RAS shape  (81, 106, 76)\n"
     ]
    }
   ],
   "source": [
    "!dipy_horizon dti_CC*trk tensor_rd.nii.gz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
